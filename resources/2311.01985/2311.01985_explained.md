# Maximizing Portfolio Predictability with Machine Learning (arXiv:2311.01985)

## Paper Snapshot
- **Authors**: Michael Pinelis, David Ruppert (Cornell University)
- **Year**: 2023 (first draft 2020)
- **Topic**: Portfolio allocation using machine learning forecasts to maximize the predictability (R-squared) of returns for S&P 500 constituents.

## Problem Statement
Traditional Markowitz allocation optimizes mean-variance trade-offs, while Maximally Predictable Portfolio (MPP) optimization seeks weights that maximize the fraction of return variance explained by conditional expectations. The unconstrained solution is a generalized eigenvector, but real portfolios require box constraints, turnover limits, and minimum return targets. The paper revisits constrained MPP optimization using modern ML forecasts of stock returns and volatilities.

## Data & Feature Pipeline
- **Universe**: Monthly S&P 500 constituents from CRSP/Compustat, May 1990 – April 2020 holdout; 1962–1969 for warm-up; 1970–1990 for rolling validation.
- **Predictors**: 15 fundamental/technical factors (momentum windows, size, volatility, turnover, valuation ratios, operating margin) aligned with Gu et al. (2020). Volatility models add lagged realized volatility.
- **Workflow**: Rolling 12-month updates. For each month `t`, models refit using data through `t-1`; forecasts generated for month `t`; covariance matrices of realized returns and forecast errors recomputed; optimization solved for weights at `t`.

## Modeling Stack
1. **Elastic Net** (Zou & Hastie, 2005) with cross-validated `α`, `λ` on validation period; controls multicollinearity while keeping sparse structure.
2. **Random Forest** with tuned tree depth, minimum leaf size, and feature subsampling. Multiple seeds averaged to reduce stochastic noise.
3. **Support Vector Regression** using radial basis kernels (`C` = 3, `γ` = 0.1 for returns; `C` = 1 for vol). Implemented via LIBSVM interface.
4. **Benchmarks**: OLS and alternative objectives (minimize raw error variance; minimize error variance per expected return).

Separate ML models are trained for returns and volatilities so that reward/risk timing can be performed on the MPP itself.

## Optimization Formulation
- **Predictability Metric**: For weights `w`, predictability `R²(w) = 1 - (wᵀEᵀEw) / (wᵀRᵀRw)` where `E` contains forecast errors and `R` realized returns.
- **Constraints**: Unit-sum weights, box bounds `0 ≤ w ≤ w̄`, optional expected return floor `μᵀw ≥ ρ`, and linear constraints `Aw ≤ b`.
- **Algorithm**: Normalized Linearization Algorithm (NLA) of Gotoh & Fujisawa (2012). Iteratively linearizes the quadratic equality `yᵀRᵀRy = 1`, solves a convex quadratic program, and renormalizes until the solution stabilizes (tolerance 10⁻³). Implementation uses CVXR in R.
- **Variants**: (i) Minimize `wᵀEᵀEw` (pure error variance), (ii) Minimize `(wᵀEᵀEw)/(wᵀμ)` (error per expected return) with similar constraints.

## Trading Strategies Built on the MPP
- **Static MPP**: Hold weights that maximize in-sample predictability under cap `w̄ ∈ {0.1, 0.3, 0.5}`.
- **Decile Portfolios**: Sort stocks by forecasted return; compare equal-weight vs. MPP-weighted long-short spreads (decile 10 minus decile 1).
- **Reward-Risk Timing**: Allocate between MPP and risk-free asset via Kelly-style weight `w_t = E[R_t - Rf_t | ℱ_{t-1}] / (γ̄ · Var[R_t | ℱ_{t-1}])` using ML forecasts for return and volatility (`γ̄ = 4`).

## Empirical Highlights (Holdout 1990–2020)
- **Predictability**: Average in-sample portfolio `R²` reaches ~21% for OLS MPP, ~16% for Elastic Net, ~14% for Random Forest under `w̄=0.3`. Forecasting volatility is easier than returns (individual stock volatility `R²` ≈ 50%).
- **Out-of-Sample Stock Forecasting**: Return `R²` near zero (0.07%–0.22%), in line with Gu et al. (2018), but volatility forecasts remain strong.
- **Performance**: Elastic Net MPP achieves 15.1% annual return, 15.2% volatility, Sharpe 0.82 with turnover ~56%. Timing the Elastic Net MPP raises excess net wealth and Sharpe (~0.90) with very low turnover (~3%).
- **Decile Weighting**: Applying MPP weights to top-decile return portfolios boosts Sharpe (e.g., Elastic Net 1st-decile MPP: 23.8% return vs. 21.7% equal-weight).
- **Consistency**: Kostly in crises (Dot-com, GFC) where predictability drops, but reward-risk timing dampens drawdowns.

## Practical Takeaways
- Use ML forecasts to estimate both expected returns and forecast-error covariance; the latter is crucial to locking in high predictability.
- Constrained fractional quadratic programs require iterative convex approximations (NLA); off-the-shelf QP solvers work once the ratio objective is linearized.
- Timing the MPP with its own forecasted Sharpe ratio substantially reduces drawdown relative to static allocation.
- High turnover from MPP weights suggests transaction cost modeling is necessary before deployment.

## Limitations & Open Questions
- Extremely low out-of-sample return `R²` means performance relies on stability of predictability rankings; regime shifts may break the approach.
- Covariance estimates ignore co-movement in volatility forecasts (diagonal assumption in timing strategy).
- Transaction costs and market impact are not modeled; MPP strategies can exceed 100% turnover.
- Implementation uses R tooling (CVXR); replicating in Python requires equivalent convex optimization stack.
- Support Vector Regression settings are fixed; richer hyperparameter searches or alternative kernels might improve or degrade robustness.

## Implementation Notes for Reproduction
1. Obtain CRSP/Compustat monthly data and align S&P 500 membership; compute predictors.
2. Run rolling 12-month refits for each model and generate forecasts for returns & volatilities.
3. Accumulate forecast errors to estimate `E` and realized returns for `R`; re-estimate covariances monthly.
4. Solve constrained MPP via NLA (or generalized eigenproblem if constraints removed).
5. Build MPP, decile, and timing portfolios; evaluate on holdout (May 1990–Apr 2020) without re-tuning.
6. Track turnover and drawdowns; stress-test on crisis windows to ensure predictability persists.

